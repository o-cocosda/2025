<!DOCTYPE html>

<html lang="en">
<head>
<base href=".."/>
<link href="assets/main.css" media="all" rel="stylesheet" type="text/css"/>
<link href="assets/favicon.ico" rel="icon" type="image/x-icon"/>
<link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&amp;display=swap" rel="stylesheet"/>
<link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400;700&amp;display=swap" rel="stylesheet"/> <!-- Link untuk font Roboto -->
<meta charset="utf-8"/>
<meta content="O-COCOSDA 2025" name="description"/>
<meta content="document" name="resource-type"/>
<meta content="global" name="distribution"/>
<meta content="Conference" name="KeyWords"/>
<title>The 28th International Conference of the Oriental COCOSDA</title>
<style>
.speaker-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
  gap: 24px;
  margin-top: 20px;
  padding: 0 10px;
}
.speaker-card {
  background: #f9f9f9;
  border-radius: 12px;
  text-align: center;
  padding: 15px;
  box-shadow: 0 2px 8px rgba(0,0,0,0.05);
}
.speaker-card img {
  width: 120px;
  height: 120px;
  border-radius: 50%;
  object-fit: cover;
  margin-bottom: 10px;
}
.speaker-card h4 {
  margin: 10px 0 5px 0;
}
.speaker-card p {
  margin: 4px 0;
}
</style></head>
<body style="margin-top: 70px;">
<!-- Navigation Bar using Flexbox -->

<div class="navigation">
<div class="dropdown">
<a class="dropbtn" href="index2.html" style="font-size:18px; font-weight:500; margin-right:15px;" title="Conference Home Page">Home â–¾</a>
<div class="dropdown-content">
<a href="index2.html#organizers" style="font-size:18px; font-weight:500; margin-right:15px;">Organizers</a>
</div>
</div>
<a href="cfp" style="font-size:18px; font-weight:500; margin-right:15px;" title="Call for Papers">Call for Papers</a>
<a href="previous.html" style="font-size:18px; font-weight:500; margin-right:15px;" title="Previous Conferences">Previous Conferences</a>
<a href="program" style="font-size:18px; font-weight:500; margin-right:15px;" title="Conference Program">Program</a>
<a href="speakers" style="font-size:18px; font-weight:500; margin-right:15px;" title="Speakers">Speakers</a>
<a href="registration" style="font-size:18px; font-weight:500; margin-right:15px;" title="Register for the Conference">Registration</a>
<a href="venue" style="font-size:18px; font-weight:500; margin-right:15px;" title="Venue">Venue</a>
<div class="dropdown">
<a class="dropbtn" href="travel" style="font-size:18px; font-weight:500; margin-right:15px;" title="Travel">Travel â–¾</a>
<div class="dropdown-content">
<a href="travel/index.html#visa-info" style="font-size:18px; font-weight:500; margin-right:15px;">Visa</a>
</div>
</div>
<a href="mailto:ococosda2025@gmail.com" style="font-size:18px; font-weight:500; margin-right:15px;" title="Contact">Contact</a>
</div>

<div style="margin-top: 100px;"></div>
<div class="top-left logo-title-wrapper">
<img alt="O-COCOSDA Logo" class="logo-image" src="assets/logo.webp"/>
<div>
<span class="title1">O-COCOSDA</span> <span class="title2">2025</span>
</div>
</div>
<div style="padding: 20px; text-align: center">
<h3>11â€“13 November 2025, <!--Royal Ambarrukmo Hotel, -->Yogyakarta, Indonesia</h3>
</div>
<div style="background-color: #ffcc00; color: #000; padding: 10px; text-align: center; font-weight: bold;">
  ðŸš§ This site is currently under construction. Content is being updated regularly. Stay tuned!
</div>
<h2>ðŸŽ¤ Keynote &amp; Invited Speakers</h2><div class="keynote" id="key_note">
<div class="part">
<div class="introduction">
<div class="intro">
<div class="intro_img">
<img alt="Jen-Tzung Chien" src="image/keynote/JEN-TZUNG.jpg"/>
</div>
<div class="intro_text">
<h3><br/><b>Learning Towards Generative and Conversational AI</b><br/><b>Speaker: Prof. <a href="https://iece.dee.nycu.edu.tw/teachers.php?pa=getItem&amp;teacher_id=124&amp;locale=tw" target="_blank" title="uninstructed">Jen-Tzung Chien</a></b>

                         Session Chair: Hsin-Min Wang, Academia Sinica, Taiwan
                        </h3><p>Lifetime Chair Professor, National Yang Ming Chiao Tung University</p>
</div>
</div>
<div class="intro_text">
<h3>
<b>Biography: </b><br/>
<b>Abstract: </b><br/>
</h3><p>Spoken dialogue systems have become crucial to build a wide range of virtual assistants for customer service, entertainment and health. These systems are composed of various components including automatic speech recognition, text-to-speech, and natural language generation, which involve delicate multimodal machine learning towards multilingual generative models. This talk will focus on state-of-the-art generative models in individual components and address how the pre-trained foundation models are utilized to re-shape the architecture via adapters, re-function the foundation via prompting and re-program the dialogue via flow control. We will also explore the challenges and opportunities through learning and integrating these components into a comprehensive conversation system.</p><p>Jen-Tzung Chien received his Ph.D. degree in electrical engineering from National Tsing Hua University, Hsinchu, Taiwan, in 1997, and is currently the Lifetime Chair Professor in National Yang Ming Chiao Tung University, Hsinchu, Taiwan. He has authored more than 250 peer-reviewed articles in machine learning, deep learning, and Bayesian learning with applications on speech and natural language processing, and three books including Bayesian Speech and Language Processing, Cambridge University Press, 2015, Source Separation and Machine Learning, Academic Press, 2018, and Machine Learning for Speaker Recognition, Cambridge University Press, 2020. He was a Tutorial Speaker of AAAI, IJCAI, ACL, KDD, ICASSP, COLING and Interspeech. He received the Best Paper Award in IEEE Workshop on Automatic Speech Recognition and Understanding in 2011, and IEEE International Workshop on Machine Learning for Signal Processing in 2023.</p>
</div>
</div>
<div style="width: 100%; height: 2px; background-color: black;margin-bottom: 50px;margin-top: 50px;margin-left: auto; margin-right: auto; "></div>
<div class="introduction">
<div class="intro">
<div class="intro_img">
<img alt="CHIN-HUI LEE" src="image/keynote/CHIN-HUI.jpg"/>
</div>
<div class="intro_text">
<h3 style="line-height: 1.5;"><br/><b>Language-Universal Speech Processing: Lessons learned from ASAT and Large Pre-trained Models with Extensions to Multilingual ASR</b><br/><b>Speaker: Prof. Chin-Hui Lee</b>

                        Session Chair: Yu Tsao, Academia Sinica, Taiwan
                        </h3><p>IEEE &amp; ISCA Fellow, Georgia Tech</p>
</div>
</div>
<div class="intro_text">
<h3><b>Biography: </b><br/>
<b>Abstract: </b><br/>
</h3><p>With recent advances in deep neural networks and large pre-trained models, the baseline
                        performances for automatic speech recognition (ASR) of resource-rich languages have
                        improved a great deal. However, only a few applications have been deployed in our daily life.
                        Part of the reason was due to past black-box approaches to ASR without leveraging upon
                        speech knowledge sources, resulting in unsatisfactory recognition results in many situations.
                        On the other hand, knowledge-based approaches, such as automatic speech attribute
                        transcription (ASAT), were not practiced in the machine-learning community due to difficulties
                        to integrate speech knowledge into building ASR system. Since speech attributes are usually
                        language-universal, they serve as an ideal set of fundamental units to build speech models.
                        They also share common distinct features among different languages such that good models
                        can also be established for speech processing to detect speech cues needed to correct
                        unexpected ASR results. In this talk, we will discuss ways the O-COCOSDA community can
                        contribute to developing robust multilingual ASR systems for many resource-limited languages
                        in this region.</p><p>Chin-Hui Lee is a professor at School of Electrical and Computer Engineering, Georgia
                        Institute of Technology. Before joining academia in 2001, he had accumulated 20 years of
                        industrial experience ending in Bell Laboratories, Murray Hill, as the Director of the Dialogue
                        Systems Research Department. Dr. Lee is a Fellow of the IEEE and a Fellow of ISCA. He has
                        published 30 patents and about 600 papers, with more than 55,000 citations and an h-index of
                        80 on Google Scholar. He received numerous awards, including the Bell Labs President's Gold
                        Award for speech recognition products in 1998. He won the SPS's 2006 Technical
                        Achievement Award for â€œExceptional Contributions to the Field of Automatic Speech
                        Recognition''. In 2012 he gave an ICASSP plenary talk on the future of automatic speech
                        recognition. In the same year he was awarded the ISCA Medal in Scientific Achievement for
                        â€œpioneering and seminal contributions to the principles and practice of automatic speech and
                        speaker recognition''. His two pioneering papers on deep regression accumulated over 2200
                        citations and won a Best Paper Award from IEEE Signal Processing Society in 2019.</p>
</div>
</div>
<div style="width: 100%; height: 2px; background-color: black;margin-bottom: 50px;margin-top: 50px;margin-left: auto; margin-right: auto; "></div>
<div class="introduction">
<div class="intro">
<div class="intro_img">
<img alt="Satoshi Nakamura" src="image/keynote/Satoshi.png"/>
</div>
<div class="intro_text">
<h3><br/><b>Recent trends in speech translation<br/></b><b>Speaker: Prof. <a href="https://sds.cuhk.edu.cn/en/teacher/1185" target="_blank" title="uninstructed">Satoshi Nakamura</a></b>

                        Session Chair: Chin-Hui Lee, Georgia Tech, USA
                        </h3><p>Professor, Chinese University of Hong Kong, Shenzhen</p>
</div>
</div>
<div class="intro_text">
<h3><b>Biography: </b><br/>
<b>Abstract: </b><br/>
</h3><p>After long research, speech translation technology has reached the level of providing a service using a smartphone. However, there are still various problems in realizing automatic simultaneous interpretation that produces the interpretation output before the end of the utterance. In this talk, I will introduce the recent research activities on automatic simultaneous speech translation and the simultaneous speech translation system developed for IWSLT shared tasks. The talk also includes research activities on speech translation, preserving para-linguistic information, and utilizing the pre-trained Large Language Models.</p><p>Dr. Satoshi Nakamura is a full professor at The Chinese University of Hong Kong, Shenzhen. He is also a professor emeritus at Nara Institute of Science and Technology (NAIST) and Honorarprofessor of Karlsruhe Institute of Technology, Germany. He received his B.S. from Kyoto Institute of Technology in 1981 and Ph.D. from Kyoto University in 1992. He was an Associate Professor in the Graduate School of Information Science at NAIST from 1994-2000. He was Department head and Director of ATR Spoken Language Communication Research Laboratories in 2000-2004, and 2005-2008, respectively, and Vice president of ATR in 2007-2008. He was Director General of Keihanna Research Laboratories and the Executive Director of Knowledge Creating Communication Research Center, National Institute of Information and Communications Technology, Japan 2009-2010. He moved to Nara Institute of Science and Technology as a full professor in 2011. He established the Data Science Center at NAIST and was a director from 2017 to 2021. He also served as a team leader of the Tourism Information Analytics Team at the AIP center of RIKEN Institute, Japan, from 2017-2021. He is currently a full professor at The Chinese University of Hong Kong, Shenzhen, China. His research interests include modeling and systems of spoken language processing, speech processing, spoken language translation, spoken dialog systems, natural language processing, and data science. He is one of the world leaders in speech-to-speech translation research. He has been serving various speech-to-speech translation research projects, including C-Star, A-Star, and the International Workshop on Spoken Language Translation IWSLT. He is currently the chairperson of ISCA SIG SLT (Spoken Language Translation). He also contributed to the standardization of the network-based speech translation at ITU-T. He was a committee member of IEEE SLTC 2016-2018. He was an Elected Board Member of the International Speech Communication Association, ISCA, from 2012 to 2019.  He received the Antonio Zampolli Prize in 2012 and retained the title of IEEE Fellow, ISCA Fellow, IPSJ Fellow, and ATR Fellow.</p>
</div>
</div>
</div>
<br/>
<footer class="site-footer">
<div style="width: 100%; margin: 0 auto;">
<p style="margin: 0; font-size: 16px; text-align: center">Â© 2025 O-COCOSDA. All rights reserved.</p>
<p style="margin: 5px 0 0; font-size: 14px; text-align: center">Oriental Chapter of the International Committee for the Co-ordination and Standardisation of Speech Databases and Assessment Techniques</p>
</div>
</footer>
<script>
  const slides = document.querySelectorAll('.slideshow-image');
  const captionElement = document.querySelector('.caption');
  const captions = [
    'The Borobudur Temple',
    'The Borobudur Temple',
    'The Yogyakarta Sultanate Palace',
    'The Yogyakarta Sultanate Palace',
    'The Serimpi Dance',
    'The Yogyakarta Monument'
  ];

  let current = 0;

  setInterval(() => {
    slides[current].classList.remove('active');
    current = (current + 1) % slides.length;
    slides[current].classList.add('active');
    captionElement.textContent = captions[current];
  }, 3000);
</script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    const links = document.querySelectorAll('.navigation > a, .navigation .dropbtn');
    const currentPath = window.location.pathname.replace(/\/$/, '');

    links.forEach(link => {
      const linkPath = new URL(link.href).pathname.replace(/\/$/, '');
      if (linkPath === currentPath) {
        link.classList.add('active');
      }
    });
  });
</script>
</div></body>
</html>
